# io.jl
# This module contains the two functions required to read vtk files and
# retrieve coordinate data from them

module IO

include("geometry.jl")

using .Geometry: convert_to_cylindrical

export read_vtk_file, retrieve_coordinates, extract_points, get_mesh_bounds, split_data, match_split_data, save_vtk_file


"""
    save_vtk_file(file::String, data::Dict)

Write the given data to a legacy ASCII VTK file in POLYDATA format. The input `data` dictionary 
should contain at least a `:points` key (an N×3 matrix of point coordinates) and may contain 
additional keys:
  - `:cells`: A dictionary of cell connectivity information. Each key should be a Symbol representing 
    the cell type (e.g. :vertices, :lines, etc.), and its value is a dictionary with keys:
      - `:offsets`: A vector of integers.
      - `:connectivity`: A vector of integers.
  - `:point_data`: A dictionary of attributes associated with each point. Each field can be either 
    a vector (length N, treated as 1-component) or an N×M matrix (treated as an M-component field).

The file is written in a way that is compatible with the output of `read_vtk_file`, PyVista, and 
visualization tools like ParaView.

# Arguments
- file::String: Path to the output VTK file.
- data::Dict: Dictionary containing the polydata with required key `:points` and optionally `:cells`
  and `:point_data`.

# Returns
Nothing. The function writes the VTK file to disk.

# Raises
- ArgumentError: If the required keys are missing or if the dimensions of the data are inconsistent.
"""
function save_vtk_file(file::String, data::Dict)
    # Validate that the data has the required :points key
    if !haskey(data, :points)
        throw(ArgumentError("Data dictionary must contain key :points"))
    end
    points = data[:points]
    # Ensure points is an N×3 matrix
    if ndims(points) != 2 || size(points, 2) != 3
        throw(ArgumentError("The :points array must be an N×3 matrix."))
    end
    N = size(points, 1)

    open(file, "w") do io
        # Write header lines
        println(io, "# vtk DataFile Version 5.1")
        println(io, "vtk output generated by Packing3D.jl: https://github.com/fjbarter/Packing3D.jl")
        println(io, "ASCII")
        println(io, "DATASET POLYDATA")

        # Write the POINTS section
        println(io, "POINTS $N float")
        for i in 1:N
            println(io, join(points[i, :], " "))
        end

        # If cell connectivity data is provided, write the cell sections.
        if haskey(data, :cells)
            cells = data[:cells]
            # For each cell section (e.g., :vertices, :lines, etc.)
            for (k, cell_data) in cells
                # k is a Symbol; output its uppercase string (e.g. "VERTICES")
                # The header should have: <length(OFFSETS)> and <length(CONNECTIVITY)>
                println(io, uppercase(String(k)), " ", length(cell_data[:offsets]), " ", length(cell_data[:connectivity]))
                # Write the OFFSETS block.
                println(io, "OFFSETS vtktypeint64")
                println(io, join(cell_data[:offsets], " "))
                # Write the CONNECTIVITY block.
                println(io, "CONNECTIVITY vtktypeint64")
                println(io, join(cell_data[:connectivity], " "))
            end
        end

        # If point data is provided, write the POINT_DATA section using a FIELD block.
        if haskey(data, :point_data)
            point_data = data[:point_data]
            println(io, "POINT_DATA $N")
            # Gather all fields that have data for all points.
            fields = [k for (k, v) in point_data if (isa(v, AbstractVector) && length(v) == N) ||
                                                   (isa(v, AbstractMatrix) && size(v, 1) == N)]
            num_fields = length(fields)
            println(io, "FIELD FieldData $num_fields")
            for k in fields
                v = point_data[k]
                # Determine number of components and flatten data appropriately.
                if isa(v, AbstractVector) && length(v) == N
                    num_components = 1
                    flat = string.(v)
                elseif isa(v, AbstractMatrix) && size(v, 1) == N
                    num_components = size(v, 2)
                    # Flatten in row-major order: use transpose then vec.
                    flat = string.(vec(transpose(v)))
                else
                    @warn "Skipping field $(k): dimensions do not match number of points"
                    continue
                end
                # Determine the VTK data type based on the element type.
                T = eltype(v)
                vtk_type = ""
                if T <: Integer
                    vtk_type = "int"
                elseif T <: AbstractFloat
                    vtk_type = (T == Float64) ? "double" : "float"
                else
                    @warn "Skipping field $(k): unsupported element type $(T)"
                    continue
                end
                # Write header line for this field.
                field_header = "$(k) $num_components $N $vtk_type"
                println(io, field_header)
                # Write the field data values in groups for readability.
                group_size = 9
                for i in 1:group_size:length(flat)
                    last_index = min(i + group_size - 1, length(flat))
                    println(io, join(flat[i:last_index], " "))
                end
            end
        end
    end
    return nothing
end


"""
    median(v::AbstractVector)

Computes the median of the input vector. For an even number of elements, the median is defined
as the average of the two middle values.

# Arguments
- `v::AbstractVector`: A vector of numeric values.

# Returns
The median of the vector.

# Raises
- `ArgumentError` if the input vector is empty.
"""
function median(v::AbstractVector)
    n = length(v)
    if n == 0
        throw(ArgumentError("Cannot compute median of an empty vector"))
    end
    # Copy the vector so that the original data is not mutated.
    v_sorted = copy(v)
    sort!(v_sorted)
    mid = div(n, 2)
    if isodd(n)
        return v_sorted[mid+1]
    else
        return (v_sorted[mid] + v_sorted[mid+1]) / 2
    end
end

@inline function read_cell_section(io, keyword::String, file)
    # Read the header line, e.g. "VERTICES 6 5"
    header = strip(readline(io))
    parts = split(header)
    if length(parts) < 3
        throw(ArgumentError("Invalid $keyword header line: '$header'"))
    end
    # For polyvertex cells, the convention is:
    #   first number = number of tokens in offsets array,
    #   second number = number of tokens in connectivity array.
    num_offsets = parse(Int, parts[2])
    num_connectivity = parse(Int, parts[3])
    
    # --- OFFSETS block ---
    # Expect an OFFSETS header line; skip it.
    offsets_header = strip(readline(io))
    if !startswith(offsets_header, "OFFSETS")
        throw(ArgumentError("Expected OFFSETS block after $keyword header, got: '$offsets_header', file: $file"))
    end
    # Skip any type annotation line (if present)
    candidate = strip(readline(io))
    if !isempty(candidate) && !isdigit(candidate[1])
        # Candidate is a type line; skip it and read the next line.
        offsets_tokens = String[]
    else
        # Candidate already contains tokens.
        offsets_tokens = split(candidate)
    end
    # Continue reading lines until we have exactly num_offsets tokens.
    while length(offsets_tokens) < num_offsets && !eof(io)
        line = strip(readline(io))
        if isempty(line)
            continue
        end
        append!(offsets_tokens, split(line))
    end
    if length(offsets_tokens) != num_offsets
        throw(ArgumentError("Expected $num_offsets OFFSETS tokens in $keyword section, got $(length(offsets_tokens)). file: $file"))
    end
    offsets = parse.(Int, offsets_tokens)
    
    # --- CONNECTIVITY block ---
    # Expect a CONNECTIVITY header line. (skipping one possibly blank line)
    connectivity_header = strip(readline(io))
    if isempty(connectivity_header)
        connectivity_header = strip(readline(io))
    end
    if !startswith(connectivity_header, "CONNECTIVITY")
        throw(ArgumentError("Expected CONNECTIVITY block after OFFSETS in $keyword section, got: '$connectivity_header', file: $file"))
    end
    # Optionally, there may be a type line; check the next line.
    candidate = strip(readline(io))
    connectivity_tokens = String[]
    if !isempty(candidate) && !isdigit(candidate[1])
        # Candidate is a type line; skip it.
        connectivity_tokens = String[]
    else
        connectivity_tokens = split(candidate)
    end
    while length(connectivity_tokens) < num_connectivity && !eof(io)
        line = strip(readline(io))
        if isempty(line)
            continue
        end
        append!(connectivity_tokens, split(line))
    end
    if length(connectivity_tokens) != num_connectivity
        throw(ArgumentError("Expected $num_connectivity CONNECTIVITY tokens in $keyword section, got $(length(connectivity_tokens))."))
    end
    connectivity = parse.(Int, connectivity_tokens)
    
    return Dict(:offsets => offsets, :connectivity => connectivity)
end



function read_vtk_file(file::String; verbose::Bool=true)
    # Quick check on file existence
    if !isfile(file)
        throw(ArgumentError("The file '$file' does not exist. Please provide a valid path."))
    end

    points_accum = Float64[]
    point_data = Dict{Symbol,Any}()
    cells = Dict{Symbol,Any}()

    in_point_data = false
    expected_point_data_count = 0
    fields_to_read = 0

    open(file, "r") do io
        # --- Header lines ---
        header_line1 = readline(io)  # e.g. "# vtk DataFile Version 5.1"
        header_line2 = readline(io)  # e.g. "Generated by LIGGGHTS"
        format_line  = strip(readline(io))  # "ASCII" or "BINARY"
        dataset_line = strip(readline(io))   # e.g. "DATASET POLYDATA"

        if format_line != "ASCII"
            throw(ArgumentError("Only ASCII format is supported. Found '$format_line' instead."))
        end
        ds_split = split(dataset_line)
        if length(ds_split) < 2 || ds_split[1] != "DATASET" || ds_split[2] != "POLYDATA"
            throw(ArgumentError("Only 'DATASET POLYDATA' is supported. Found '$dataset_line' instead."))
        end
        header_line1 = nothing; header_line2 = nothing; format_line  = nothing; dataset_line = nothing

        # --- Step 1: Read POINTS section ---
        num_points = 0
        points_parsed = false
        while !eof(io) && !points_parsed
            line = strip(readline(io))
            if isempty(line)
                continue
            end
            if startswith(line, "POINTS")
                parts = split(line)
                if length(parts) < 3
                    throw(ArgumentError("Invalid 'POINTS' line: '$line'"))
                end
                num_points = parse(Int, parts[2])
                total_needed = 3 * num_points
                points_accum = Vector{Float64}(undef, total_needed)
                index = 1
                while index <= total_needed
                    coords_line = strip(readline(io))
                    if isempty(coords_line)
                        continue
                    end
                    for c in split(coords_line)
                        val = tryparse(Float64, c)
                        if val === nothing
                            throw(ArgumentError("Invalid numeric value in POINTS section: '$c'"))
                        end
                        points_accum[index] = val
                        index += 1
                    end
                end
                points_parsed = true
            end
        end
        if length(points_accum) != 3 * num_points
            throw(ArgumentError("Number of coordinate values read does not match '3 * num_points'."))
        end

        # --- Step 1.5: Read cell sections ---
        cell_keywords = Set(["VERTICES","LINES","POLYGONS","TRIANGLE_STRIPS"])
        while !eof(io)
            let pos = position(io)
                line = strip(readline(io))
                if isempty(line)
                    continue
                end

                # if we’ve hit the start of point_data ⇒ rewind & exit
                if startswith(line, "POINT_DATA")
                    seek(io, pos)
                    break
                end

                # only try to parse if this is truly a cell keyword
                first_tok = uppercase(first(split(line)))
                if first_tok ∉ cell_keywords
                    # not a cell block—rewind and exit
                    seek(io, pos)
                    break
                end

                # it is a cell block: rewind, try to parse it, but on error bail out
                seek(io, pos)
                try
                    cells[Symbol(lowercase(first_tok))] = read_cell_section(io, first_tok, file)
                    # continue looping in case there are multiple cell blocks
                catch err
                    if verbose @warn "Malformed $first_tok block; skipping topology: $err" end
                    # record an “empty” cell entry
                    cells[Symbol(lowercase(first_tok))] = Dict(:offsets=>Int[], :connectivity=>Int[])
                    # rewind to let POINT_DATA finder see that header (or next token)
                    seek(io, pos)
                    break
                end
            end
        end

        # --- Step 2: Skip lines until we hit "POINT_DATA" ---
        while !eof(io)
            pos = position(io)
            line = strip(readline(io))
            if startswith(line, "POINT_DATA")
                seek(io, pos)
                break
            end
        end

        # --- Step 3: Read POINT_DATA ---
        while !eof(io)
            line = strip(readline(io))
            if isempty(line)
                continue
            end
            if startswith(line, "POINT_DATA")
                parts = split(line)
                if length(parts) < 2
                    throw(ArgumentError("Malformed 'POINT_DATA' line: '$line'"))
                end
                in_point_data = true
                expected_point_data_count = parse(Int, parts[2])
            elseif in_point_data && startswith(line, "SCALARS")
                scalars_split = split(line)
                if length(scalars_split) < 3
                    throw(ArgumentError("Invalid SCALARS definition: '$line'"))
                end
                scalar_name = Symbol(scalars_split[2])
                num_components = 1
                if length(scalars_split) >= 4
                    val = tryparse(Int, scalars_split[4])
                    if val !== nothing
                        num_components = val
                    end
                end
                if !eof(io)
                    _ = strip(readline(io))  # typically "LOOKUP_TABLE default"
                end
                total_vals_needed = expected_point_data_count * num_components
                data_accum = Vector{Float64}(undef, total_vals_needed)
                i = 1
                while i <= total_vals_needed && !eof(io)
                    vals_line = strip(readline(io))
                    if isempty(vals_line)
                        continue
                    end
                    for v in split(vals_line)
                        data_accum[i] = parse(Float64, v)
                        i += 1
                    end
                end
                if length(data_accum) != total_vals_needed
                    throw(ArgumentError("Did not read the expected number of scalar values for '$scalar_name'."))
                end
                if num_components > 1
                    point_data[scalar_name] = reshape(data_accum, (num_components, expected_point_data_count))'
                else
                    point_data[scalar_name] = data_accum
                end
            elseif in_point_data && startswith(line, "FIELD")
                parts = split(line)
                if length(parts) < 3
                    throw(ArgumentError("Invalid FIELD line: '$line'"))
                end
                fields_to_read = parse(Int, parts[3])
                while fields_to_read > 0 && !eof(io)
                    field_line = strip(readline(io))
                    if isempty(field_line)
                        continue
                    end
                    field_parts = split(field_line)
                    if length(field_parts) < 4
                        throw(ArgumentError("Invalid field definition line: '$field_line'"))
                    end
                    current_field_name = Symbol(field_parts[1])
                    current_field_components = parse(Int, field_parts[2])
                    current_field_points = parse(Int, field_parts[3])
                    total_field_vals = current_field_components * current_field_points
                    collected_vals = Float64[]
                    while length(collected_vals) < total_field_vals && !eof(io)
                        val_line = strip(readline(io))
                        if isempty(val_line)
                            continue
                        end
                        for val_str in split(val_line)
                            parsed_val = tryparse(Float64, val_str)
                            if parsed_val === nothing
                                throw(ArgumentError("Invalid numeric value in FIELD '$current_field_name': '$val_str'"))
                            end
                            push!(collected_vals, parsed_val)
                        end
                    end
                    if length(collected_vals) != total_field_vals
                        throw(ArgumentError("Did not read expected number of values for FIELD '$current_field_name'."))
                    end
                    if current_field_components > 1
                        point_data[current_field_name] = reshape(collected_vals, (current_field_components, current_field_points))'
                    else
                        point_data[current_field_name] = collected_vals
                    end
                    fields_to_read -= 1
                end
            else
                continue
            end
        end
    end

    N = div(length(points_accum), 3)
    points = reshape(points_accum, (3, N))'
    out = Dict{Symbol,Any}(
        :points     => points,
        :point_data => point_data,
        :cells      => cells           # now guaranteed to exist, even if empty
    )
    return out
end


# """
#     read_vtk_file(file::String; verbose::Bool=true)

# Reads a legacy‐VTK file (ASCII or BINARY) in POLYDATA format and returns a dictionary with keys:
#   - `:points` (an N×3 Array{Float64,2}),
#   - `:cells` (a Dict mapping cell‐type Symbols to Dicts with keys `:offsets` and `:connectivity`),
#   - `:point_data` (a Dict mapping Symbol → Array of data).

# Dispatches to an ASCII reader or a BINARY reader helper based on the third header line.
# """
# function read_vtk_file_binaries(file::String; verbose::Bool = true)
#     if !isfile(file)
#         throw(ArgumentError("The file '$file' does not exist. Please provide a valid path."))
#     end

#     # Peek at the format line (third line) to decide ASCII vs. BINARY
#     open(file, "r") do io
#         _ = readline(io)                     # e.g. "# vtk DataFile Version 5.1"
#         _ = readline(io)                     # comment
#         format_line = strip(readline(io))    # "ASCII" or "BINARY"
#         if format_line == "ASCII"
#             return _read_ascii_vtk_file(file; verbose = verbose)
#         elseif format_line == "BINARY"
#             return _read_binary_vtk_file(file; verbose = verbose)
#         else
#             throw(ArgumentError("Only 'ASCII' or 'BINARY' formats are supported. Found '$format_line'."))
#         end
#     end
# end


# # -----------------------------------------------------------------------------
# # Helper: exact copy of the original ASCII‐only reader, unchanged except that
# # read_cell_section now allows “OFFSETS vtktypeint64” or similar type tokens.
# # -----------------------------------------------------------------------------

# @inline function read_cell_section(io, keyword::String, file)
#     # Read the header line, e.g. "POLYGONS 6 5"
#     header = strip(readline(io))
#     parts = split(header)
#     if length(parts) < 3
#         throw(ArgumentError("Invalid $keyword header line: '$header'"))
#     end
#     num_offsets      = parse(Int, parts[2])
#     num_connectivity = parse(Int, parts[3])

#     # --- OFFSETS block ---
#     offsets_header = strip(readline(io))
#     # Allow lines like "OFFSETS", "OFFSETS vtktypeint64", or "OFFSETS vtkIdType"
#     if !startswith(offsets_header, "OFFSETS")
#         throw(ArgumentError("Expected OFFSETS block after $keyword header, got: '$offsets_header', file: $file"))
#     end
#     # Skip any type‐annotation line (e.g. "vtktypeint64") if present
#     candidate = strip(readline(io))
#     offsets_tokens = String[]
#     if !isempty(candidate) && !isdigit(candidate[1])
#         # candidate is a type annotation; skip it
#         # and read the next nonempty line(s) into offsets_tokens
#     else
#         # candidate already contains numeric tokens
#         append!(offsets_tokens, split(candidate))
#     end
#     while length(offsets_tokens) < num_offsets && !eof(io)
#         line = strip(readline(io))
#         if isempty(line)
#             continue
#         end
#         append!(offsets_tokens, split(line))
#     end
#     if length(offsets_tokens) != num_offsets
#         throw(ArgumentError("Expected $num_offsets OFFSETS tokens in $keyword section, got $(length(offsets_tokens)). file: $file"))
#     end
#     offsets = parse.(Int, offsets_tokens)

#     # --- CONNECTIVITY block ---
#     conn_header = strip(readline(io))
#     if isempty(conn_header)
#         conn_header = strip(readline(io))
#     end
#     # Allow "CONNECTIVITY" or "CONNECTIVITY vtktypeint64"
#     if !startswith(conn_header, "CONNECTIVITY")
#         throw(ArgumentError("Expected CONNECTIVITY block after OFFSETS in $keyword section, got: '$conn_header', file: $file"))
#     end
#     # Skip any type annotation if present
#     candidate = strip(readline(io))
#     connectivity_tokens = String[]
#     if !isempty(candidate) && !isdigit(candidate[1])
#         # candidate is a type annotation; skip it
#     else
#         append!(connectivity_tokens, split(candidate))
#     end
#     while length(connectivity_tokens) < num_connectivity && !eof(io)
#         line = strip(readline(io))
#         if isempty(line)
#             continue
#         end
#         append!(connectivity_tokens, split(line))
#     end
#     if length(connectivity_tokens) != num_connectivity
#         throw(ArgumentError("Expected $num_connectivity CONNECTIVITY tokens in $keyword section, got $(length(connectivity_tokens))."))
#     end
#     connectivity = parse.(Int, connectivity_tokens)

#     return Dict(:offsets => offsets, :connectivity => connectivity)
# end


# function _read_ascii_vtk_file(file::String; verbose::Bool = true)
#     # This implementation is exactly the original ASCII‐only reader,
#     # except that read_cell_section now accepts "OFFSETS vtktypeint64", etc.

#     # Prepare accumulators
#     points_accum = Float64[]
#     point_data    = Dict{Symbol,Any}()
#     cells         = Dict{Symbol,Any}()
#     in_point_data = false
#     expected_point_data_count = 0
#     fields_to_read = 0

#     open(file, "r") do io
#         # --- Header lines ---
#         _ = readline(io)    # e.g. "# vtk DataFile Version 5.1"
#         _ = readline(io)    # comment
#         _ = strip(readline(io))  # "ASCII"
#         dataset_line = strip(readline(io))   # e.g. "DATASET POLYDATA"
#         ds_split = split(dataset_line)
#         if length(ds_split) < 2 || ds_split[1] != "DATASET" || ds_split[2] != "POLYDATA"
#             throw(ArgumentError("Only 'DATASET POLYDATA' is supported. Found '$dataset_line' instead."))
#         end

#         # --- Step 1: Read POINTS section ---
#         num_points = 0
#         points_parsed = false
#         while !eof(io) && !points_parsed
#             line = strip(readline(io))
#             if isempty(line)
#                 continue
#             end
#             if startswith(line, "POINTS")
#                 parts = split(line)
#                 if length(parts) < 3
#                     throw(ArgumentError("Invalid 'POINTS' line: '$line'"))
#                 end
#                 num_points = parse(Int, parts[2])
#                 total_needed = 3 * num_points
#                 points_accum = Vector{Float64}(undef, total_needed)
#                 idx = 1
#                 while idx <= total_needed
#                     coords_line = strip(readline(io))
#                     if isempty(coords_line)
#                         continue
#                     end
#                     for c in split(coords_line)
#                         val = tryparse(Float64, c)
#                         if val === nothing
#                             throw(ArgumentError("Invalid numeric value in POINTS section: '$c'"))
#                         end
#                         points_accum[idx] = val
#                         idx += 1
#                     end
#                 end
#                 points_parsed = true
#             end
#         end
#         if length(points_accum) != 3 * num_points
#             throw(ArgumentError("Number of coordinate values read does not match '3 * num_points'."))
#         end

#         # --- Step 1.5: Read cell sections ---
#         cell_keywords = Set(["VERTICES","LINES","POLYGONS","TRIANGLE_STRIPS"])
#         while !eof(io)
#             let pos = position(io)
#                 line = strip(readline(io))
#                 if isempty(line)
#                     continue
#                 end
#                 if startswith(line, "POINT_DATA")
#                     seek(io, pos)
#                     break
#                 end
#                 first_tok = uppercase(first(split(line)))
#                 if first_tok ∉ cell_keywords
#                     seek(io, pos)
#                     break
#                 end
#                 seek(io, pos)
#                 try
#                     cells[Symbol(lowercase(first_tok))] = read_cell_section(io, first_tok, file)
#                 catch err
#                     if verbose
#                         @warn "Malformed $first_tok block; skipping topology: $err"
#                     end
#                     cells[Symbol(lowercase(first_tok))] = Dict(:offsets => Int[], :connectivity => Int[])
#                     seek(io, pos)
#                     break
#                 end
#             end
#         end

#         # --- Step 2: Skip lines until "POINT_DATA" ---
#         while !eof(io)
#             pos = position(io)
#             line = strip(readline(io))
#             if startswith(line, "POINT_DATA")
#                 seek(io, pos)
#                 break
#             end
#         end

#         # --- Step 3: Read POINT_DATA ---
#         while !eof(io)
#             line = strip(readline(io))
#             if isempty(line)
#                 continue
#             end
#             if startswith(line, "POINT_DATA")
#                 parts = split(line)
#                 if length(parts) < 2
#                     throw(ArgumentError("Malformed 'POINT_DATA' line: '$line'"))
#                 end
#                 in_point_data = true
#                 expected_point_data_count = parse(Int, parts[2])
#             elseif in_point_data && startswith(line, "SCALARS")
#                 scalars_split = split(line)
#                 if length(scalars_split) < 3
#                     throw(ArgumentError("Invalid SCALARS definition: '$line'"))
#                 end
#                 scalar_name = Symbol(scalars_split[2])
#                 num_components = 1
#                 if length(scalars_split) >= 4
#                     val = tryparse(Int, scalars_split[4])
#                     if val !== nothing
#                         num_components = val
#                     end
#                 end
#                 _ = strip(readline(io))  # "LOOKUP_TABLE default"
#                 total_vals_needed = expected_point_data_count * num_components
#                 data_accum = Vector{Float64}(undef, total_vals_needed)
#                 i = 1
#                 while i <= total_vals_needed && !eof(io)
#                     vals_line = strip(readline(io))
#                     if isempty(vals_line)
#                         continue
#                     end
#                     for v in split(vals_line)
#                         data_accum[i] = parse(Float64, v)
#                         i += 1
#                     end
#                 end
#                 if length(data_accum) != total_vals_needed
#                     throw(ArgumentError("Did not read the expected number of scalar values for '$scalar_name'."))
#                 end
#                 if num_components > 1
#                     point_data[scalar_name] = reshape(data_accum, (num_components, expected_point_data_count))'
#                 else
#                     point_data[scalar_name] = data_accum
#                 end

#             elseif in_point_data && startswith(line, "FIELD")
#                 parts = split(line)
#                 if length(parts) < 3
#                     throw(ArgumentError("Invalid FIELD line: '$line'"))
#                 end
#                 fields_to_read = parse(Int, parts[3])
#                 while fields_to_read > 0 && !eof(io)
#                     field_line = strip(readline(io))
#                     if isempty(field_line)
#                         continue
#                     end
#                     field_parts = split(field_line)
#                     if length(field_parts) < 4
#                         throw(ArgumentError("Invalid field definition line: '$field_line'"))
#                     end
#                     current_field_name      = Symbol(field_parts[1])
#                     current_field_components = parse(Int, field_parts[2])
#                     current_field_points    = parse(Int, field_parts[3])
#                     total_field_vals = current_field_components * current_field_points
#                     collected_vals = Float64[]
#                     while length(collected_vals) < total_field_vals && !eof(io)
#                         val_line = strip(readline(io))
#                         if isempty(val_line)
#                             continue
#                         end
#                         for val_str in split(val_line)
#                             parsed_val = tryparse(Float64, val_str)
#                             if parsed_val === nothing
#                                 throw(ArgumentError("Invalid numeric value in FIELD '$current_field_name': '$val_str'"))
#                             end
#                             push!(collected_vals, parsed_val)
#                         end
#                     end
#                     if length(collected_vals) != total_field_vals
#                         throw(ArgumentError("Did not read expected number of values for FIELD '$current_field_name'."))
#                     end
#                     if current_field_components > 1
#                         point_data[current_field_name] = reshape(collected_vals, (current_field_components, current_field_points))'
#                     else
#                         point_data[current_field_name] = collected_vals
#                     end
#                     fields_to_read -= 1
#                 end

#             else
#                 continue
#             end
#         end
#     end

#     # Reshape points
#     N = div(length(points_accum), 3)
#     points = reshape(points_accum, (3, N))'
#     return Dict{Symbol,Any}(
#         :points     => points,
#         :point_data => point_data,
#         :cells      => cells
#     )
# end


# # -----------------------------------------------------------------------------
# # Helper: new BINARY‐only reader.  Shares logic for dataset‐/POINTS/etc. but
# # reads all numeric arrays as big‐endian binary.  Does not call read_cell_section.
# # -----------------------------------------------------------------------------

# function _read_binary_vtk_file(file::String; verbose::Bool = true)
#     # Prepare accumulators
#     points_accum = Float64[]
#     point_data    = Dict{Symbol,Any}()
#     cells         = Dict{Symbol,Any}()
#     in_point_data = false
#     expected_point_data_count = 0
#     fields_to_read = 0

#     open(file, "r") do io
#         # --- HEADER LINES ---
#         _ = readline(io)                         # "# vtk DataFile Version 5.1"
#         _ = readline(io)                         # comment
#         _ = strip(readline(io))                  # "BINARY"
#         dataset_line = strip(readline(io))       # "DATASET POLYDATA"
#         ds_split = split(dataset_line)
#         if length(ds_split) < 2 || ds_split[1] != "DATASET" || ds_split[2] != "POLYDATA"
#             throw(ArgumentError("Only 'DATASET POLYDATA' is supported. Found '$dataset_line' instead."))
#         end

#         # --- Step 1: Read POINTS section in binary ---
#         num_points = 0
#         points_parsed = false
#         while !eof(io) && !points_parsed
#             line = strip(readline(io))
#             if isempty(line)
#                 continue
#             end
#             if startswith(line, "POINTS")
#                 # Example: "POINTS 100 float" or "POINTS 100 double"
#                 parts = split(line)
#                 if length(parts) < 3
#                     throw(ArgumentError("Invalid 'POINTS' line: '$line'"))
#                 end
#                 num_points = parse(Int, parts[2])
#                 dtype_str  = lowercase(parts[3])       # "float" or "double"
#                 total_vals = 3 * num_points

#                 if dtype_str == "float"
#                     # Read big‐endian Float32
#                     raw_u = Vector{UInt32}(undef, total_vals)
#                     read!(io, raw_u)
#                     points_accum = Vector{Float64}(undef, total_vals)
#                     for i in 1:total_vals
#                         be_u32 = bswap(raw_u[i])
#                         f32    = reinterpret(Float32, be_u32)
#                         points_accum[i] = Float64(f32)
#                     end
#                 elseif dtype_str == "double"
#                     # Read big‐endian Float64
#                     raw_u = Vector{UInt64}(undef, total_vals)
#                     read!(io, raw_u)
#                     points_accum = Vector{Float64}(undef, total_vals)
#                     for i in 1:total_vals
#                         be_u64 = bswap(raw_u[i])
#                         f64    = reinterpret(Float64, be_u64)
#                         points_accum[i] = f64
#                     end
#                 else
#                     throw(ArgumentError("Unsupported POINTS data type '$dtype_str'. Expected 'float' or 'double'."))
#                 end
#                 points_parsed = true
#             end
#         end
#         if length(points_accum) != 3 * num_points
#             throw(ArgumentError("Number of coordinate values read does not match '3 * num_points'."))
#         end

#         # --- Step 1.5: Read cell sections in binary ---
#         cell_keywords = Set(["VERTICES","LINES","POLYGONS","TRIANGLE_STRIPS"])
#         while !eof(io)
#             let pos = position(io)
#                 line = strip(readline(io))
#                 if isempty(line)
#                     continue
#                 end
#                 if startswith(line, "POINT_DATA")
#                     seek(io, pos)
#                     break
#                 end
#                 first_tok = uppercase(first(split(line)))
#                 if first_tok ∉ cell_keywords
#                     seek(io, pos)
#                     break
#                 end

#                 # It is a cell block
#                 # Read header: e.g. "POLYGONS M P"
#                 header = strip(readline(io))
#                 parts = split(header)
#                 if length(parts) < 3
#                     throw(ArgumentError("Invalid $first_tok header line: '$header'"))
#                 end
#                 num_offsets      = parse(Int, parts[2])
#                 num_connectivity = parse(Int, parts[3])

#                 # OFFSETS (possibly with type token)
#                 offsets_header = strip(readline(io))
#                 if !startswith(offsets_header, "OFFSETS")
#                     throw(ArgumentError("Expected OFFSETS block after $first_tok header, got: '$offsets_header'"))
#                 end
#                 # If the header line included "OFFSETS vtktypeint64", we already consumed it.
#                 # Next, read raw Int32 or Int64 depending on type–but legacy VTK uses 32‐bit ints here.
#                 raw_u_off = Vector{UInt32}(undef, num_offsets)
#                 read!(io, raw_u_off)
#                 offsets = Vector{Int}(undef, num_offsets)
#                 for i in 1:num_offsets
#                     be_u32 = bswap(raw_u_off[i])
#                     offsets[i] = Int(be_u32)
#                 end

#                 # CONNECTIVITY (possibly with type token)
#                 conn_header = strip(readline(io))
#                 if !startswith(conn_header, "CONNECTIVITY")
#                     throw(ArgumentError("Expected CONNECTIVITY block after OFFSETS in $first_tok section, got: '$conn_header'"))
#                 end
#                 raw_u_conn = Vector{UInt32}(undef, num_connectivity)
#                 read!(io, raw_u_conn)
#                 connectivity = Vector{Int}(undef, num_connectivity)
#                 for i in 1:num_connectivity
#                     be_u32 = bswap(raw_u_conn[i])
#                     connectivity[i] = Int(be_u32)
#                 end

#                 cells[Symbol(lowercase(parts[1]))] = Dict(
#                     :offsets      => offsets,
#                     :connectivity => connectivity
#                 )
#             end
#         end

#         # --- Step 2: Skip lines until "POINT_DATA" ---
#         while !eof(io)
#             pos = position(io)
#             line = strip(readline(io))
#             if startswith(line, "POINT_DATA")
#                 seek(io, pos)
#                 break
#             end
#         end

#         # --- Step 3: Read POINT_DATA in binary ---
#         while !eof(io)
#             line = strip(readline(io))
#             if isempty(line)
#                 continue
#             end

#             if startswith(line, "POINT_DATA")
#                 parts = split(line)
#                 if length(parts) < 2
#                     throw(ArgumentError("Malformed 'POINT_DATA' line: '$line'"))
#                 end
#                 in_point_data = true
#                 expected_point_data_count = parse(Int, parts[2])
#                 continue
#             end

#             # SCALARS block
#             if in_point_data && startswith(line, "SCALARS")
#                 scalars_split = split(line)
#                 if length(scalars_split) < 3
#                     throw(ArgumentError("Invalid SCALARS definition: '$line'"))
#                 end
#                 scalar_name = Symbol(scalars_split[2])
#                 data_type   = lowercase(scalars_split[3])  # "float", "double", "int", etc.
#                 num_components = 1
#                 if length(scalars_split) >= 4
#                     tmp = tryparse(Int, scalars_split[4])
#                     if tmp !== nothing
#                         num_components = tmp
#                     end
#                 end
#                 _ = strip(readline(io))  # "LOOKUP_TABLE default"
#                 total_vals_needed = expected_point_data_count * num_components

#                 if data_type == "float"
#                     raw_u = Vector{UInt32}(undef, total_vals_needed)
#                     read!(io, raw_u)
#                     data_accum = Vector{Float64}(undef, total_vals_needed)
#                     for j in 1:total_vals_needed
#                         be_u32 = bswap(raw_u[j])
#                         f32   = reinterpret(Float32, be_u32)
#                         data_accum[j] = Float64(f32)
#                     end
#                 elseif data_type == "double"
#                     raw_u = Vector{UInt64}(undef, total_vals_needed)
#                     read!(io, raw_u)
#                     data_accum = Vector{Float64}(undef, total_vals_needed)
#                     for j in 1:total_vals_needed
#                         be_u64 = bswap(raw_u[j])
#                         f64    = reinterpret(Float64, be_u64)
#                         data_accum[j] = f64
#                     end
#                 elseif data_type == "int" || data_type == "long"
#                     raw_u = Vector{UInt32}(undef, total_vals_needed)
#                     read!(io, raw_u)
#                     data_accum = Vector{Int}(undef, total_vals_needed)
#                     for j in 1:total_vals_needed
#                         be_u32 = bswap(raw_u[j])
#                         data_accum[j] = Int(be_u32)
#                     end
#                 else
#                     throw(ArgumentError("Unsupported SCALARS data type '$data_type' for '$scalar_name'."))
#                 end

#                 if num_components > 1
#                     point_data[scalar_name] = reshape(data_accum, (num_components, expected_point_data_count))'
#                 else
#                     point_data[scalar_name] = data_accum
#                 end

#             # FIELD block
#             elseif in_point_data && startswith(line, "FIELD")
#                 parts = split(line)
#                 if length(parts) < 3
#                     throw(ArgumentError("Invalid FIELD line: '$line'"))
#                 end
#                 fields_to_read = parse(Int, parts[3])
#                 while fields_to_read > 0 && !eof(io)
#                     field_line = strip(readline(io))
#                     if isempty(field_line)
#                         continue
#                     end
#                     field_parts = split(field_line)
#                     if length(field_parts) < 4
#                         throw(ArgumentError("Invalid field definition line: '$field_line'"))
#                     end
#                     current_field_name       = Symbol(field_parts[1])
#                     current_field_components = parse(Int, field_parts[2])
#                     current_field_points     = parse(Int, field_parts[3])
#                     data_type                = lowercase(field_parts[4])
#                     total_field_vals = current_field_components * current_field_points

#                     if data_type == "float"
#                         raw_u = Vector{UInt32}(undef, total_field_vals)
#                         read!(io, raw_u)
#                         float_vals = Vector{Float64}(undef, total_field_vals)
#                         for j in 1:total_field_vals
#                             be_u32 = bswap(raw_u[j])
#                             f32   = reinterpret(Float32, be_u32)
#                             float_vals[j] = Float64(f32)
#                         end
#                         if current_field_components > 1
#                             point_data[current_field_name] = reshape(float_vals, (current_field_components, current_field_points))'
#                         else
#                             point_data[current_field_name] = float_vals
#                         end

#                     elseif data_type == "double"
#                         raw_u = Vector{UInt64}(undef, total_field_vals)
#                         read!(io, raw_u)
#                         float_vals = Vector{Float64}(undef, total_field_vals)
#                         for j in 1:total_field_vals
#                             be_u64 = bswap(raw_u[j])
#                             f64    = reinterpret(Float64, be_u64)
#                             float_vals[j] = f64
#                         end
#                         if current_field_components > 1
#                             point_data[current_field_name] = reshape(float_vals, (current_field_components, current_field_points))'
#                         else
#                             point_data[current_field_name] = float_vals
#                         end

#                     elseif data_type == "int" || data_type == "long"
#                         raw_u = Vector{UInt32}(undef, total_field_vals)
#                         read!(io, raw_u)
#                         int_vals = Vector{Int}(undef, total_field_vals)
#                         for j in 1:total_field_vals
#                             be_u32 = bswap(raw_u[j])
#                             int_vals[j] = Int(be_u32)
#                         end
#                         if current_field_components > 1
#                             point_data[current_field_name] = reshape(int_vals, (current_field_components, current_field_points))'
#                         else
#                             point_data[current_field_name] = int_vals
#                         end

#                     else
#                         throw(ArgumentError("Unsupported FIELD data type '$data_type' for '$current_field_name'."))
#                     end

#                     fields_to_read -= 1
#                 end

#             else
#                 continue
#             end
#         end
#     end

#     # Reshape points
#     N = div(length(points_accum), 3)
#     points = reshape(points_accum, (3, N))'
#     return Dict{Symbol,Any}(
#         :points     => points,
#         :point_data => point_data,
#         :cells      => cells
#     )
# end




"""
    get_mesh_bounds(mesh_file::Dict)

Computes the axis-aligned bounding box of a mesh based on its point coordinates.

# Arguments
- `mesh_file::Dict`: Dictionary containing mesh data, as produced by `read_vtk_file`. 
  It must include the key `:points`, which should be an N×3 matrix of point coordinates.

# Returns
A vector of 6 numbers in the form `[x_min, x_max, y_min, y_max, z_min, z_max]` representing 
the minimum and maximum bounds of the mesh along the x, y, and z axes respectively.

# Raises
- `ErrorException`: If the mesh file cannot be read, if the `:points` key is missing, 
  or if the points array is not in the expected N×3 format.
"""
function get_mesh_bounds(mesh_file::String)
    # Attempt to read the VTK file, and throw an error if it fails.
    mesh_data = try
        read_vtk_file(mesh_file)
    catch err
        error("Failed to read mesh file: $(err)")
    end

    # Ensure that the mesh_data contains the :points key.
    if !haskey(mesh_data, :points)
        error("Mesh data does not contain a ':points' field.")
    end

    # Extract the points array once.
    points = mesh_data[:points]

    # Validate that the points array is a 2D matrix with 3 columns (nx3).
    if ndims(points) != 2 || size(points, 2) != 3
        error("The ':points' array must be an nx3 matrix, but got an array with size $(size(points)).")
    end

    # Compute the bounds for each coordinate (x, y, z) by iterating over columns.
    bounds = [val for col in 1:3 for val in (minimum(points[:, col]), maximum(points[:, col]))]

    # bounds is returned as [x_min, x_max, y_min, y_max, z_min, z_max]
    return bounds
end


"""
    split_data(data::Dict{Symbol, Any}; split_by::Symbol = :x, threshold=nothing, value1=nothing, value2=nothing, tolerance=1e-6)

Determines a splitting of the data by returning two sets of point IDs (from `data[:point_data][:id]`)
that correspond to two subsets of the data. This function is intended to be run once at the beginning
of a study.

# Parameters
- `data::Dict{Symbol, Any}`: A dataset containing `:points` and `:point_data`.
- `split_by::Symbol`: The characteristic to split on. Acceptable values include:
  - Cartesian coordinates: `:x`, `:y`, or `:z` (which are taken from the appropriate column of `data[:points]`)
  - Cylindrical coordinates: `:r` or `:theta` (obtained from `retrieve_coordinates` and `convert_to_cylindrical`)
  - Particle properties: e.g. `:radius` or `:type` (taken from `data[:point_data]`)
- `threshold`: For splitting by particle properties, if provided, points with values below the threshold
  are assigned to subset 1, and those with values greater than or equal to the threshold are assigned to subset 2.
- `value1` and `value2`: For splitting by particle properties. If both are provided (and no threshold is given),
  the function will select points within a tolerance of each target value.
- `tolerance::Real`: A tolerance factor used when comparing against `value1` and `value2`.

# Returns
A tuple `(data_1_ids, data_2_ids)` where each is a set of point IDs (as integers) corresponding to the
two split subsets.

# Raises
- An error if the input data does not contain required keys.
- An error if the splitting results in an incomplete allocation (e.g. one subset gets all or none of the points).
"""
function split_data(data::Dict{Symbol, Any}; split_by::Symbol = :x, threshold=nothing, value1=nothing, value2=nothing, tolerance=1e-6)
    # Check that data has required keys.
    for key in (:points, :point_data)
        if !haskey(data, key)
            error("Input data must contain key: $key")
        end
    end
    if !haskey(data[:point_data], :id)
        error("point_data has no 'id' field")
    end

    # For splitting by particle properties, ensure the key exists (unless splitting spatially)
    if split_by ∉ (:r, :theta, :x, :y, :z) && !haskey(data[:point_data], split_by)
        error("point_data does not contain the key: $split_by")
    end

    # Determine the splitting values.
    xyz_symbols = [:x, :y, :z]
    if split_by in xyz_symbols
        # For Cartesian coordinates, get the corresponding column from :points.
        axis_index = findfirst(isequal(split_by), xyz_symbols)
        split_values = data[:points][:, axis_index]
    elseif split_by in (:r, :theta)
        # Convert Cartesian to cylindrical coordinates.
        x_data, y_data, z_data, _ = retrieve_coordinates(data)
        r_data, theta_data = convert_to_cylindrical(x_data, y_data)
        split_values = (split_by == :r) ? r_data : theta_data
    elseif split_by in (:radius, :type)
        split_values = data[:point_data][split_by]
    else
        error("Invalid split_by argument. Use :x, :y, :z, :r, :theta, :radius, or :type.")
    end

    # Decide on splitting strategy.
    if split_by in (:x, :y, :z, :r, :theta)
        # For spatial coordinates, split at the median.
        median_val = median(split_values)
        mask1 = split_values .< median_val
        mask2 = split_values .>= median_val
    elseif split_by in (:radius, :type)
        if threshold !== nothing
            # Use threshold splitting.
            mask1 = split_values .< threshold
            mask2 = split_values .>= threshold
        elseif value1 !== nothing && value2 !== nothing
            # Use tolerance matching when both target values are provided.
            rel_tolerance = tolerance * abs(value1)
            mask1 = abs.(split_values .- value1) .< rel_tolerance
            mask2 = abs.(split_values .- value2) .< rel_tolerance
        else
            println("Warning: Not enough target values provided for $split_by; using median split.")
            median_val = median(split_values)
            mask1 = split_values .< median_val
            mask2 = split_values .>= median_val
        end
    end

    # Verify that every point is allocated.
    total_points = length(data[:points][:, 1])
    n1 = count(mask1)
    n2 = count(mask2)
    if n1 + n2 < total_points
        error("Incomplete splitting: some points were not allocated (data_1: $n1, data_2: $n2, total: $total_points).")
    elseif n1 == total_points
        error("Incomplete splitting: all data assigned to subset 1 ($split_by, threshold: $threshold, value1: $value1, value2: $value2)")
    elseif n2 == total_points
        error("Incomplete splitting: all data assigned to subset 2 ($split_by, threshold: $threshold, value1: $value1, value2: $value2)")
    end

    # Return only the ID lists, converting them to integers.
    ids = data[:point_data][:id]
    data_1_ids = Set(round.(Int, ids[mask1]))
    data_2_ids = Set(round.(Int, ids[mask2]))
    return data_1_ids, data_2_ids
end



"""
    match_split_data(data::Dict, data_1_ids::Vector{Int}, data_2_ids::Vector{Int})

Given a dataset and two lists of point IDs, this function partitions the data into two subsets.
This is intended for use on subsequent files (after the initial study split).

# Parameters
- `data::Dict`: A dataset containing `:points` and `:point_data`.
- `data_1_ids::Vector{Int}`: The IDs corresponding to the first subset (obtained from `split_data`).
- `data_2_ids::Vector{Int}`: The IDs corresponding to the second subset.

# Returns
A tuple `(data_1, data_2)` where each is a subset of `data` (structured as a dictionary) that
contains only the points with matching IDs.
"""
function match_split_data(data::Dict, data_1_ids::Set{Int}, data_2_ids::Set{Int})
    # Get the complete list of IDs from the current dataset.
    ids = data[:point_data][:id]
    # Create boolean masks based on membership in the provided ID lists.
    mask1 = [id in data_1_ids for id in ids]
    mask2 = [id in data_2_ids for id in ids]
    # Extract the subsets using the helper function.
    data_1 = extract_points(data, mask1)
    data_2 = extract_points(data, mask2)
    return data_1, data_2
end



"""
    extract_points(data::Dict{Symbol, Any}, mask::Union{BitVector, AbstractVector{Bool}})

Extracts a subset of points and their associated data based on the provided mask.

# Parameters
- `data::Dict{Symbol, Any}`: The dataset containing `:points` and `:point_data`.
- `mask::Union{BitVector, AbstractVector{Bool}}`: A boolean array where `true` indicates the points to be extracted.

# Returns
- `subset::Dict{Symbol, Any}`: A dictionary containing the extracted `:points` and `:point_data`.
"""
function extract_points(data::Dict{Symbol, Any}, mask::Union{BitVector, AbstractVector{Bool}})
    # Validate inputs
    num_points = size(data[:points], 1)
    if length(mask) != num_points
        throw(ArgumentError("Length of mask ($length(mask)) does not match number of points ($num_points)."))
    end

    # Extract points
    extracted_points = data[:points][mask, :]

    # Extract point data
    extracted_point_data = Dict{Symbol, Any}()
    for (key, value) in data[:point_data]
        if isa(value, AbstractVector)
            # If the data is a vector, extract using mask directly to preserve it as a vector
            extracted_point_data[key] = value[mask]
        elseif isa(value, AbstractMatrix) && size(value, 1) == num_points
            # If the data is a matrix, extract rows using mask to preserve the matrix structure
            extracted_point_data[key] = value[mask, :]
        else
            throw(ArgumentError("Point data for '$key' does not match number of points or is of unsupported type."))
        end
    end

    return Dict(
        :points => extracted_points,
        :point_data => extracted_point_data
    )
end


"""
    retrieve_coordinates(data::Dict)

Extracts x, y, z coordinates and radii from the dataset.

# Arguments
- `data::Dict`: The data structure returned by `read_vtk_file`.

# Returns
A tuple with:
- `x_data`: Array of x-coordinates.
- `y_data`: Array of y-coordinates.
- `z_data`: Array of z-coordinates.
- `radii`: Array of radii (extracted from `point_data[:radius]`).

# Raises
- `KeyError`: If the `radius` attribute is not found in `point_data`.
"""
function retrieve_coordinates(data::Dict)
    # Extract points from the dataset
    points = data[:points]
    if size(points, 2) != 3
        throw(ArgumentError("The points array must have three columns (x, y, z coordinates)."))
    end

    x_data = points[:, 1]  # x-coordinates
    y_data = points[:, 2]  # y-coordinates
    z_data = points[:, 3]  # z-coordinates

    # Extract radii from point_data
    if haskey(data[:point_data], :radius)
        radii = data[:point_data][:radius]
    else
        throw(KeyError("The dataset does not contain the 'radius' attribute."))
    end

    return x_data, y_data, z_data, radii
end

end # module IO
